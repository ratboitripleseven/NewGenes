{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import pygraphviz\n",
    "from pandas import read_csv\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Methods used\n",
    "\n",
    "Non Deep-Learning:\n",
    "- LightGBM\n",
    "- HistGradientBoostingClassifier\n",
    "- XGBoost\n",
    "\n",
    "Deep-Learning: (in progress)\n",
    "- FeedForward/MLP\n",
    "    - single works\n",
    "    - all species is giving back weird error (check dataset first prolly there)\n",
    "- Multi-task Learning (in progress)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non DL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD Single or All"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Josefa:\n",
    "\n",
    "I checked the database again and find out how they calculated SD1,SD2,SD3 and SDT \n",
    "\n",
    "Basically for each genome, the HGTdb website gave its mean value and standard deviation for GC1,GC2,GC3 and GCT \n",
    "eg (https://usuaris.tinet.cat/debb/HGT/ecoli.d/welcome.html)\n",
    "\n",
    "basically SD1 = (GC1 of gene - GC1 mean)/(standard deviation)\n",
    "\n",
    "basically we can actually delete, for every gene GC1,GC2,GC3 and GCT and uses for each gene\n",
    "SD1,SD2,SD3 and SDT \n",
    "\n",
    "My though process on data type D:\n",
    "To create a model that does not look at the GC content of genome under study.. instead how far off genes (in comparision to host genome)\n",
    "\n",
    "Added another data type E:\n",
    "basically just data type D with strand, AADev, length, Mah (Data type B without GC)... Data B currently is the best performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.machine_learning.data_loader import ml_load_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4276, 13)\n",
      "(4276, 12)\n",
      "(4276, 10)\n",
      "(4276, 4)\n",
      "(4276, 8)\n"
     ]
    }
   ],
   "source": [
    "X_ecoli_A, y_ecoli_A = ml_load_species('ecoli', 'A')\n",
    "X_ecoli_B, y_ecoli_B = ml_load_species('ecoli', 'B')\n",
    "X_ecoli_C, y_ecoli_C = ml_load_species('ecoli', 'C')\n",
    "X_ecoli_D, y_ecoli_D = ml_load_species('ecoli', 'D')\n",
    "X_ecoli_E, y_ecoli_E = ml_load_species('ecoli', 'E')\n",
    "print(X_ecoli_A.shape)\n",
    "print(X_ecoli_B.shape)\n",
    "print(X_ecoli_C.shape)\n",
    "print(X_ecoli_D.shape)\n",
    "print(X_ecoli_E.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195187, 8)\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all = ml_load_species('all','E')\n",
    "print(X_all.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n",
    "X_ecoli_A_train, X_ecoli_A_test, Y_ecoli_A_train, Y_ecoli_A_test = train_test_split(X_ecoli_A, y_ecoli_A, test_size=0.20, shuffle=False)\n",
    "# B wocogcode\n",
    "X_ecoli_B_train, X_ecoli_B_test, Y_ecoli_B_train, Y_ecoli_B_test = train_test_split(X_ecoli_B, y_ecoli_B, test_size=0.20, shuffle=False)\n",
    "# C wocatfeat\n",
    "X_ecoli_C_train, X_ecoli_C_test, Y_ecoli_C_train, Y_ecoli_C_test = train_test_split(X_ecoli_C, y_ecoli_C, test_size=0.20, shuffle=False)\n",
    "# D \n",
    "X_ecoli_D_train, X_ecoli_D_test, Y_ecoli_D_train, Y_ecoli_D_test = train_test_split(X_ecoli_D, y_ecoli_D, test_size=0.20, shuffle=False)\n",
    "# E \n",
    "X_ecoli_E_train, X_ecoli_E_test, Y_ecoli_E_train, Y_ecoli_E_test = train_test_split(X_ecoli_E, y_ecoli_E, test_size=0.20, shuffle=False)\n",
    "\n",
    "# print(X_coliEC_D_train.shape, Y_coliEC_D_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle=False make sure that we can compare the effect on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 63 nan 22.7 -5.9 68.2 6.3 63.6 1.0 51.5 0.0 422.6 1]\n",
      "[  0.   63.   22.7  -5.9  68.2   6.3  63.6   1.   51.5   0.  422.6   1. ]\n",
      "[ 63.   22.7  -5.9  68.2   6.3  63.6   1.   51.5   0.  422.6]\n",
      "[-5.9  6.3  1.   0. ]\n",
      "[  0.   63.   -5.9   6.3   1.    0.  422.6   1. ]\n"
     ]
    }
   ],
   "source": [
    "print(X_ecoli_A_train[0])\n",
    "print(X_ecoli_B_train[0])\n",
    "print(X_ecoli_C_train[0])\n",
    "print(X_ecoli_D_train[0])\n",
    "print(X_ecoli_E_train[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single on ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.machine_learning.trainer import ml_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type B ****\n",
      "\n",
      "average_precision: 0.611 (0.065)\n",
      "[[776  29]\n",
      " [ 23  28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       805\n",
      "         1.0       0.49      0.55      0.52        51\n",
      "\n",
      "    accuracy                           0.94       856\n",
      "   macro avg       0.73      0.76      0.74       856\n",
      "weighted avg       0.94      0.94      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecoli_B_lgbm = LGBMClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_B_lgbm,'ecoli','B',cv,'average_precision',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type C ****\n",
      "\n",
      "roc_auc: 0.931 (0.022)\n",
      "[[776  29]\n",
      " [ 24  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       805\n",
      "         1.0       0.48      0.53      0.50        51\n",
      "\n",
      "    accuracy                           0.94       856\n",
      "   macro avg       0.73      0.75      0.74       856\n",
      "weighted avg       0.94      0.94      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecoli_C_lgbm = LGBMClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_C_lgbm,'ecoli','C',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type D ****\n",
      "\n",
      "roc_auc: 0.930 (0.020)\n",
      "[[778  27]\n",
      " [ 26  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       805\n",
      "         1.0       0.48      0.49      0.49        51\n",
      "\n",
      "    accuracy                           0.94       856\n",
      "   macro avg       0.72      0.73      0.73       856\n",
      "weighted avg       0.94      0.94      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecoli_D_lgbm = LGBMClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_D_lgbm,'ecoli','D',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type E ****\n",
      "\n",
      "roc_auc: 0.933 (0.020)\n",
      "[[773  32]\n",
      " [ 22  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       805\n",
      "         1.0       0.48      0.57      0.52        51\n",
      "\n",
      "    accuracy                           0.94       856\n",
      "   macro avg       0.72      0.76      0.74       856\n",
      "weighted avg       0.94      0.94      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecoli_E_lgbm = LGBMClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_B_lgbm,'ecoli','E',cv,'roc_auc',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type B ****\n",
      "\n",
      "roc_auc: 0.943 (0.002)\n",
      "[[35251   596]\n",
      " [ 2183  1008]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.63      0.32      0.42      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.79      0.65      0.69     39038\n",
      "weighted avg       0.92      0.93      0.92     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_B_lgbm = LGBMClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_B_lgbm,'all','B',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type C ****\n",
      "\n",
      "roc_auc: 0.943 (0.002)\n",
      "[[35248   599]\n",
      " [ 2191  1000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.63      0.31      0.42      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.78      0.65      0.69     39038\n",
      "weighted avg       0.92      0.93      0.92     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_C_lgbm = LGBMClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_C_lgbm,'all','C',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type D ****\n",
      "\n",
      "roc_auc: 0.933 (0.002)\n",
      "[[35272   575]\n",
      " [ 2357   834]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.59      0.26      0.36      3191\n",
      "\n",
      "    accuracy                           0.92     39038\n",
      "   macro avg       0.76      0.62      0.66     39038\n",
      "weighted avg       0.91      0.92      0.91     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_D_lgbm = LGBMClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_D_lgbm,'all','D',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type E ****\n",
      "\n",
      "roc_auc: 0.939 (0.002)\n",
      "[[35265   582]\n",
      " [ 2187  1004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.63      0.31      0.42      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.79      0.65      0.69     39038\n",
      "weighted avg       0.92      0.93      0.92     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_E_lgbm = LGBMClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_E_lgbm,'all','E',cv,'roc_auc',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HistGradientBoostingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single on ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type B ****\n",
      "\n",
      "roc_auc: 0.929 (0.024)\n",
      "[[776  29]\n",
      " [ 22  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       805\n",
      "         1.0       0.50      0.57      0.53        51\n",
      "\n",
      "    accuracy                           0.94       856\n",
      "   macro avg       0.74      0.77      0.75       856\n",
      "weighted avg       0.94      0.94      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "ecoli_B_HGBC = HistGradientBoostingClassifier(random_state=1)\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_B_HGBC,'ecoli','B',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type C ****\n",
      "\n",
      "roc_auc: 0.929 (0.023)\n",
      "[[773  32]\n",
      " [ 23  28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       805\n",
      "         1.0       0.47      0.55      0.50        51\n",
      "\n",
      "    accuracy                           0.94       856\n",
      "   macro avg       0.72      0.75      0.74       856\n",
      "weighted avg       0.94      0.94      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "ecoli_C_HGBC = HistGradientBoostingClassifier(random_state=1)\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_C_HGBC,'ecoli','C',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type D ****\n",
      "\n",
      "roc_auc: 0.930 (0.023)\n",
      "[[773  32]\n",
      " [ 24  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       805\n",
      "         1.0       0.46      0.53      0.49        51\n",
      "\n",
      "    accuracy                           0.93       856\n",
      "   macro avg       0.71      0.74      0.73       856\n",
      "weighted avg       0.94      0.93      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "ecoli_D_HGBC = HistGradientBoostingClassifier(random_state=1)\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_D_HGBC,'ecoli','D',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type E ****\n",
      "\n",
      "roc_auc: 0.933 (0.021)\n",
      "[[772  33]\n",
      " [ 19  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97       805\n",
      "         1.0       0.49      0.63      0.55        51\n",
      "\n",
      "    accuracy                           0.94       856\n",
      "   macro avg       0.73      0.79      0.76       856\n",
      "weighted avg       0.95      0.94      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "ecoli_E_HGBC = HistGradientBoostingClassifier(random_state=1)\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_E_HGBC,'ecoli','E',cv,'roc_auc',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type B ****\n",
      "\n",
      "roc_auc: 0.943 (0.002)\n",
      "[[35237   610]\n",
      " [ 2182  1009]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.62      0.32      0.42      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.78      0.65      0.69     39038\n",
      "weighted avg       0.92      0.93      0.92     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_B_HGBC = HistGradientBoostingClassifier(random_state=1)\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_B_HGBC,'all','B',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type C ****\n",
      "\n",
      "roc_auc: 0.943 (0.002)\n",
      "[[35229   618]\n",
      " [ 2151  1040]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.63      0.33      0.43      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.78      0.65      0.70     39038\n",
      "weighted avg       0.92      0.93      0.92     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_C_HGBC = HistGradientBoostingClassifier(random_state=1)\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_C_HGBC,'all','C',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type D ****\n",
      "\n",
      "roc_auc: 0.933 (0.002)\n",
      "[[35287   560]\n",
      " [ 2367   824]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.60      0.26      0.36      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.77      0.62      0.66     39038\n",
      "weighted avg       0.91      0.93      0.91     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_D_HGBC = HistGradientBoostingClassifier(random_state=1)\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_D_HGBC,'all','D',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type E ****\n",
      "\n",
      "roc_auc: 0.939 (0.002)\n",
      "[[35239   608]\n",
      " [ 2178  1013]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.62      0.32      0.42      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.78      0.65      0.69     39038\n",
      "weighted avg       0.92      0.93      0.92     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_E_HGBC = HistGradientBoostingClassifier(random_state=1)\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_E_HGBC,'all','E',cv,'roc_auc',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single on ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type B ****\n",
      "\n",
      "roc_auc: 0.925 (0.022)\n",
      "[[774  31]\n",
      " [ 23  28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       805\n",
      "         1.0       0.47      0.55      0.51        51\n",
      "\n",
      "    accuracy                           0.94       856\n",
      "   macro avg       0.72      0.76      0.74       856\n",
      "weighted avg       0.94      0.94      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "ecoli_B_XGB = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_B_XGB,'ecoli','B',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type C ****\n",
      "\n",
      "roc_auc: 0.926 (0.021)\n",
      "[[775  30]\n",
      " [ 29  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       805\n",
      "         1.0       0.42      0.43      0.43        51\n",
      "\n",
      "    accuracy                           0.93       856\n",
      "   macro avg       0.69      0.70      0.70       856\n",
      "weighted avg       0.93      0.93      0.93       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "ecoli_C_XGB = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_C_XGB,'ecoli','C',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type D ****\n",
      "\n",
      "roc_auc: 0.928 (0.021)\n",
      "[[773  32]\n",
      " [ 24  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       805\n",
      "         1.0       0.46      0.53      0.49        51\n",
      "\n",
      "    accuracy                           0.93       856\n",
      "   macro avg       0.71      0.74      0.73       856\n",
      "weighted avg       0.94      0.93      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "ecoli_D_XGB = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_D_XGB,'ecoli','D',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on ecoli with type E ****\n",
      "\n",
      "roc_auc: 0.929 (0.020)\n",
      "[[775  30]\n",
      " [ 22  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       805\n",
      "         1.0       0.49      0.57      0.53        51\n",
      "\n",
      "    accuracy                           0.94       856\n",
      "   macro avg       0.73      0.77      0.75       856\n",
      "weighted avg       0.94      0.94      0.94       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "ecoli_E_XGB = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(ecoli_E_XGB,'ecoli','E',cv,'roc_auc',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type B ****\n",
      "\n",
      "roc_auc: 0.944 (0.002)\n",
      "[[35140   707]\n",
      " [ 2082  1109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.61      0.35      0.44      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.78      0.66      0.70     39038\n",
      "weighted avg       0.92      0.93      0.92     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "all_B_XGB = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_B_XGB,'all','B',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type C ****\n",
      "\n",
      "roc_auc: 0.944 (0.002)\n",
      "[[35161   686]\n",
      " [ 2066  1125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.62      0.35      0.45      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.78      0.67      0.71     39038\n",
      "weighted avg       0.92      0.93      0.92     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "all_C_XGB = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_C_XGB,'all','C',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type D ****\n",
      "\n",
      "roc_auc: 0.932 (0.002)\n",
      "[[35246   601]\n",
      " [ 2339   852]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.59      0.27      0.37      3191\n",
      "\n",
      "    accuracy                           0.92     39038\n",
      "   macro avg       0.76      0.63      0.66     39038\n",
      "weighted avg       0.91      0.92      0.91     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "all_D_XGB = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_D_XGB,'all','D',cv,'roc_auc',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training on all with type E ****\n",
      "\n",
      "roc_auc: 0.939 (0.002)\n",
      "[[35214   633]\n",
      " [ 2163  1028]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     35847\n",
      "         1.0       0.62      0.32      0.42      3191\n",
      "\n",
      "    accuracy                           0.93     39038\n",
      "   macro avg       0.78      0.65      0.69     39038\n",
      "weighted avg       0.92      0.93      0.92     39038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "all_E_XGB = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "ml_trainer(all_E_XGB,'all','E',cv,'roc_auc',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.deep_learning.data_loader import SingleSpecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gc_signature': array([ 0.000e+00,  1.173e+03,  3.980e+01, -2.200e+00,  2.450e+01,\n",
       "        -2.200e+00,  2.810e+01, -2.100e+00,  3.080e+01, -3.000e+00,\n",
       "         1.490e+01,  1.000e+00]),\n",
       " 'hgt': 1.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_single = SingleSpecies(species=\"bsub\",data_type=\"B\")\n",
    "\n",
    "test_single[500]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.deep_learning.data_loader import AllSpecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "           Strand  Length   GC1  SD1   GC2  SD2   GC3  SD3   GCT  SDT    Mah   \n",
      "ID                                                                             \n",
      "nana_3260     NaN       0  60.4  0.9  31.6 -1.5  44.3 -0.4  45.4 -0.4   19.6  \\\n",
      "nanb_3261     NaN       0  58.5  0.6  40.1  0.6  45.5 -0.2  48.0  0.3    9.3   \n",
      "nanb_1695     NaN       0  53.0 -0.4  34.5 -0.9  54.2  0.6  47.2 -0.2   34.2   \n",
      "nana_1696     NaN       0  34.1 -4.6  29.3 -2.3  31.7 -2.9  31.7 -4.8  326.1   \n",
      "SCO3176       1.0    1749   NaN  NaN   NaN  NaN   NaN  NaN   NaN  NaN    NaN   \n",
      "\n",
      "           AADev  HGT  \n",
      "ID                     \n",
      "nana_3260      1    0  \n",
      "nanb_3261      1    0  \n",
      "nanb_1695      1    0  \n",
      "nana_1696      1    0  \n",
      "SCO3176        0    0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gc_signature': tensor([0.0000e+00, 4.0200e+02, 3.9300e+01, 3.0000e-01, 4.5900e+01, 3.5000e+00,\n",
       "         2.0700e+01, 0.0000e+00, 3.5300e+01, 1.9000e+00, 1.6320e+02, 1.0000e+00],\n",
       "        dtype=torch.float64),\n",
       " 'hgt': tensor(0., dtype=torch.float64)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all = AllSpecies(data_type=\"B\")\n",
    "\n",
    "test_all[500]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classifier MLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/biaslyai/pytorch-introduction-to-neural-network-feedforward-neural-network-model-e7231cff47cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Feedforward, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = torch.nn.Linear(self.input_size, 100).double()\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(100, 1).double()\n",
    "        self.sigmoid1 = torch.nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid1(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for MTL need to change \n",
    "\n",
    "class MTLFeedforward(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Feedforward, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = torch.nn.Linear(self.input_size, 100).double()\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(100, 50).double()\n",
    "        \n",
    "        \n",
    "        # Layers for species classification\n",
    "        self.species_relu1 = torch.nn.ReLU()\n",
    "        self.species_fc1 = torch.nn.Linear(50, 1).double()\n",
    "        self.species_sigmoid1 = torch.nn.Sigmoid()\n",
    "        \n",
    "        # Layers for HGT classifications\n",
    "        self.hgt_relu1 = torch.nn.ReLU()\n",
    "        self.hgt_fc1 = torch.nn.Linear(50, 1).double()\n",
    "        self.hgt_sigmoid1 = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # fw pass to species layer\n",
    "        x_species = self.species_relu1(x)\n",
    "        x_species = self.species_fc1(x_species)\n",
    "        x_species = self.species_sigmoid1(x_species)\n",
    "        \n",
    "        # fw pass to species layer\n",
    "        x_hgt = self.hgt_relu1(x)\n",
    "        x_hgt = self.hgt_fc1(x_hgt)\n",
    "        x_hgt = self.hgt_sigmoid1(x_hgt)\n",
    "        \n",
    "        \n",
    "        return x_species, x_hgt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function: trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.deep_learning.trainer import Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classifier Trained on single species"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### init data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for single species\n",
    "ecoli_B_set= SingleSpecies(species=\"ecoli\",data_type=\"B\")\n",
    "ecoli_C_set= SingleSpecies(species=\"ecoli\",data_type=\"C\")\n",
    "ecoli_D_set= SingleSpecies(species=\"ecoli\",data_type=\"D\")\n",
    "ecoli_E_set= SingleSpecies(species=\"ecoli\",data_type=\"E\")\n",
    "\n",
    "# partition\n",
    "# Partitioning like this is not good. \n",
    "# Prolly do a csv partitioning again so it is somewhat more reproducible\n",
    "ecoli_B_train_set, ecoli_B_test_set = torch.utils.data.random_split(ecoli_B_set, [0.7, 0.3])\n",
    "ecoli_C_train_set, ecoli_C_test_set = torch.utils.data.random_split(ecoli_C_set, [0.7, 0.3])\n",
    "ecoli_D_train_set, ecoli_D_test_set = torch.utils.data.random_split(ecoli_D_set, [0.7, 0.3])\n",
    "ecoli_E_train_set, ecoli_E_test_set = torch.utils.data.random_split(ecoli_E_set, [0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gc_signature': array([ 0.00e+00,  5.46e+02,  6.01e+01,  3.00e-01,  3.99e+01, -1.00e-01,\n",
      "        5.79e+01,  4.00e-01,  5.26e+01,  3.00e-01,  2.46e+01,  1.00e+00]), 'hgt': 0.0}\n",
      "{'gc_signature': array([1101. ,   45.7,   -2.1,   27.7,   -2.9,   33.4,   -2.6,   35.6,\n",
      "         -3.2,   16.3]), 'hgt': 1.0}\n",
      "{'gc_signature': array([-1.1,  1.4, -0.5, -0.3]), 'hgt': 0.0}\n",
      "{'gc_signature': array([ 0.000e+00,  1.002e+03,  1.200e+00,  1.000e+00, -5.000e-01,\n",
      "        6.000e-01,  1.290e+01,  1.000e+00]), 'hgt': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(ecoli_B_train_set[0])\n",
    "print(ecoli_C_train_set[0])\n",
    "print(ecoli_D_train_set[0])\n",
    "print(ecoli_E_train_set[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 3.4214953573115516\n",
      "EPOCH 2:\n",
      "LOSS train 1.2520247603435526\n",
      "EPOCH 3:\n",
      "LOSS train 0.5771831622110641\n",
      "EPOCH 4:\n",
      "LOSS train 0.39535662853452874\n",
      "EPOCH 5:\n",
      "LOSS train 0.3494302204837994\n",
      "EPOCH 6:\n",
      "LOSS train 0.33462268718869903\n",
      "EPOCH 7:\n",
      "LOSS train 0.32725941945975695\n",
      "EPOCH 8:\n",
      "LOSS train 0.32203289615911695\n",
      "EPOCH 9:\n",
      "LOSS train 0.32018248829778667\n",
      "EPOCH 10:\n",
      "LOSS train 0.31692508641399236\n",
      "EPOCH 11:\n",
      "LOSS train 0.31380003853452443\n",
      "EPOCH 12:\n",
      "LOSS train 0.3111193341865896\n",
      "EPOCH 13:\n",
      "LOSS train 0.31076782787326857\n",
      "EPOCH 14:\n",
      "LOSS train 0.30827637951569753\n",
      "EPOCH 15:\n",
      "LOSS train 0.3080431990042782\n",
      "EPOCH 16:\n",
      "LOSS train 0.3053316019669697\n",
      "EPOCH 17:\n",
      "LOSS train 0.3041932128238745\n",
      "EPOCH 18:\n",
      "LOSS train 0.30331871846449177\n",
      "EPOCH 19:\n",
      "LOSS train 0.30311918960163897\n",
      "EPOCH 20:\n",
      "LOSS train 0.3026257736239527\n"
     ]
    }
   ],
   "source": [
    "ecoli_B_classifier = Classifier(Feedforward(12),torch.nn.BCELoss(), torch.optim.Adam,0.00001)\n",
    "ecoli_B_classifier.train(ecoli_B_train_set, 5,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 2.1744859579745106\n",
      "EPOCH 2:\n",
      "LOSS train 0.38089901222470646\n",
      "EPOCH 3:\n",
      "LOSS train 0.3348017417785868\n",
      "EPOCH 4:\n",
      "LOSS train 0.32245541985765847\n",
      "EPOCH 5:\n",
      "LOSS train 0.31357476294154296\n",
      "EPOCH 6:\n",
      "LOSS train 0.3097535535441396\n",
      "EPOCH 7:\n",
      "LOSS train 0.3045742665482406\n",
      "EPOCH 8:\n",
      "LOSS train 0.303356848816035\n",
      "EPOCH 9:\n",
      "LOSS train 0.2983815035390075\n",
      "EPOCH 10:\n",
      "LOSS train 0.2974454736823319\n",
      "EPOCH 11:\n",
      "LOSS train 0.2965568908188139\n",
      "EPOCH 12:\n",
      "LOSS train 0.29554000882101766\n",
      "EPOCH 13:\n",
      "LOSS train 0.3003131101211793\n",
      "EPOCH 14:\n",
      "LOSS train 0.29422725215689927\n",
      "EPOCH 15:\n",
      "LOSS train 0.292108851971414\n",
      "EPOCH 16:\n",
      "LOSS train 0.29295821447960535\n",
      "EPOCH 17:\n",
      "LOSS train 0.29330132094694517\n",
      "EPOCH 18:\n",
      "LOSS train 0.2947391128216287\n",
      "EPOCH 19:\n",
      "LOSS train 0.29172456795317653\n",
      "EPOCH 20:\n",
      "LOSS train 0.29097027047698554\n"
     ]
    }
   ],
   "source": [
    "ecoli_C_classifier = Classifier(Feedforward(10),torch.nn.BCELoss(), torch.optim.Adam,0.00001)\n",
    "ecoli_C_classifier.train(ecoli_C_train_set, 5,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.31665559461123866\n",
      "EPOCH 2:\n",
      "LOSS train 0.24832329665270944\n",
      "EPOCH 3:\n",
      "LOSS train 0.23494483671892752\n",
      "EPOCH 4:\n",
      "LOSS train 0.22791907392675154\n",
      "EPOCH 5:\n",
      "LOSS train 0.22302981641214556\n",
      "EPOCH 6:\n",
      "LOSS train 0.2202641857338765\n",
      "EPOCH 7:\n",
      "LOSS train 0.21840084022822828\n",
      "EPOCH 8:\n",
      "LOSS train 0.2160855691195408\n",
      "EPOCH 9:\n",
      "LOSS train 0.2151486137874429\n",
      "EPOCH 10:\n",
      "LOSS train 0.21373747222992773\n",
      "EPOCH 11:\n",
      "LOSS train 0.21116681984443056\n",
      "EPOCH 12:\n",
      "LOSS train 0.21064996643279932\n",
      "EPOCH 13:\n",
      "LOSS train 0.21186448055864038\n",
      "EPOCH 14:\n",
      "LOSS train 0.2108982067608469\n",
      "EPOCH 15:\n",
      "LOSS train 0.21124463475440328\n",
      "EPOCH 16:\n",
      "LOSS train 0.2109814915363215\n",
      "EPOCH 17:\n",
      "LOSS train 0.20898984060329887\n",
      "EPOCH 18:\n",
      "LOSS train 0.2091291941214206\n",
      "EPOCH 19:\n",
      "LOSS train 0.2091217259078254\n",
      "EPOCH 20:\n",
      "LOSS train 0.21042171552471453\n"
     ]
    }
   ],
   "source": [
    "ecoli_D_classifier = Classifier(Feedforward(4),torch.nn.BCELoss(), torch.optim.Adam,0.001)\n",
    "ecoli_D_classifier.train(ecoli_D_train_set, 5,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.906980384816023\n",
      "EPOCH 2:\n",
      "LOSS train 0.6924047927882065\n",
      "EPOCH 3:\n",
      "LOSS train 0.6183962320582325\n",
      "EPOCH 4:\n",
      "LOSS train 0.5654943359405175\n",
      "EPOCH 5:\n",
      "LOSS train 0.6857722903103958\n",
      "EPOCH 6:\n",
      "LOSS train 0.7190535973257559\n",
      "EPOCH 7:\n",
      "LOSS train 0.49188293220255924\n",
      "EPOCH 8:\n",
      "LOSS train 0.5905085982096737\n",
      "EPOCH 9:\n",
      "LOSS train 0.5111248401961138\n",
      "EPOCH 10:\n",
      "LOSS train 0.5592117121783459\n",
      "EPOCH 11:\n",
      "LOSS train 0.4703963749841636\n",
      "EPOCH 12:\n",
      "LOSS train 0.5040785971270321\n",
      "EPOCH 13:\n",
      "LOSS train 0.574630162195057\n",
      "EPOCH 14:\n",
      "LOSS train 0.5545703778592008\n",
      "EPOCH 15:\n",
      "LOSS train 0.41598716612407566\n",
      "EPOCH 16:\n",
      "LOSS train 0.4700934209807114\n",
      "EPOCH 17:\n",
      "LOSS train 0.450022495238464\n",
      "EPOCH 18:\n",
      "LOSS train 0.45073833769926147\n",
      "EPOCH 19:\n",
      "LOSS train 0.4305160684827943\n",
      "EPOCH 20:\n",
      "LOSS train 0.41927602059447633\n"
     ]
    }
   ],
   "source": [
    "ecoli_E_classifier = Classifier(Feedforward(8),torch.nn.BCELoss(), torch.optim.Adam,0.001)\n",
    "ecoli_E_classifier.train(ecoli_E_train_set, 5,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-HGT       0.89      1.00      0.94      1412\n",
      "         HGT       0.73      0.08      0.15       196\n",
      "\n",
      "    accuracy                           0.88      1608\n",
      "   macro avg       0.81      0.54      0.54      1608\n",
      "weighted avg       0.87      0.88      0.84      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecoli_B_classifier.eval(ecoli_B_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-HGT       0.89      0.99      0.94      1420\n",
      "         HGT       0.68      0.09      0.16       188\n",
      "\n",
      "    accuracy                           0.89      1608\n",
      "   macro avg       0.79      0.54      0.55      1608\n",
      "weighted avg       0.87      0.89      0.85      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecoli_C_classifier.eval(ecoli_C_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-HGT       0.92      0.97      0.95      1425\n",
      "         HGT       0.61      0.35      0.44       183\n",
      "\n",
      "    accuracy                           0.90      1608\n",
      "   macro avg       0.77      0.66      0.69      1608\n",
      "weighted avg       0.89      0.90      0.89      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecoli_D_classifier.eval(ecoli_D_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-HGT       0.90      0.99      0.94      1415\n",
      "         HGT       0.62      0.17      0.27       193\n",
      "\n",
      "    accuracy                           0.89      1608\n",
      "   macro avg       0.76      0.58      0.60      1608\n",
      "weighted avg       0.86      0.89      0.86      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecoli_E_classifier.eval(ecoli_E_test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classifer on All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "           Strand  Length   GC1  SD1   GC2  SD2   GC3  SD3   GCT  SDT    Mah   \n",
      "ID                                                                             \n",
      "nana_3260     NaN       0  60.4  0.9  31.6 -1.5  44.3 -0.4  45.4 -0.4   19.6  \\\n",
      "nanb_3261     NaN       0  58.5  0.6  40.1  0.6  45.5 -0.2  48.0  0.3    9.3   \n",
      "nanb_1695     NaN       0  53.0 -0.4  34.5 -0.9  54.2  0.6  47.2 -0.2   34.2   \n",
      "nana_1696     NaN       0  34.1 -4.6  29.3 -2.3  31.7 -2.9  31.7 -4.8  326.1   \n",
      "SCO3176       1.0    1749   NaN  NaN   NaN  NaN   NaN  NaN   NaN  NaN    NaN   \n",
      "\n",
      "           AADev  HGT  \n",
      "ID                     \n",
      "nana_3260      1    0  \n",
      "nanb_3261      1    0  \n",
      "nanb_1695      1    0  \n",
      "nana_1696      1    0  \n",
      "SCO3176        0    0  \n"
     ]
    }
   ],
   "source": [
    "allspecies_B = AllSpecies(data_type=\"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "         Length  GC1  SD1  GC2  SD2  GC3  SD3  GCT  SDT  Mah  HGT\n",
      "ID                                                               \n",
      "SCO3176    1749  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN    0\n"
     ]
    }
   ],
   "source": [
    "allspecies_C = AllSpecies(data_type=\"C\",normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "         SD1  SD2  SD3  SDT  HGT\n",
      "ID                              \n",
      "SCO3176  NaN  NaN  NaN  NaN    0\n"
     ]
    }
   ],
   "source": [
    "allspecies_D = AllSpecies(data_type=\"D\",normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Partition data\n",
    "allspecies_B_train_set, allspecies_B_test_set = torch.utils.data.random_split(allspecies_B, [0.7, 0.3])\n",
    "allspecies_C_train_set, allspecies_C_test_set = torch.utils.data.random_split(allspecies_C, [0.7, 0.3])\n",
    "allspecies_D_train_set, allspecies_D_test_set = torch.utils.data.random_split(allspecies_D, [0.7, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gc_signature': tensor([ 0.0000e+00,  1.2360e+03,  5.6700e+01, -7.0000e-01,  4.7000e+01,\n",
      "         6.0000e-01,  4.6500e+01, -1.3000e+00,  5.0000e+01, -7.0000e-01,\n",
      "         3.3100e+01,  1.0000e+00], dtype=torch.float64), 'hgt': tensor(0., dtype=torch.float64)}\n",
      "{'gc_signature': tensor([0.0299, 0.4344, 0.4513, 0.2773, 0.3650, 0.2064, 0.4612, 0.2828, 0.6066,\n",
      "        0.0061], dtype=torch.float64), 'hgt': tensor(0., dtype=torch.float64)}\n",
      "{'gc_signature': tensor([0.5436, 0.4100, 0.4201, 0.6667], dtype=torch.float64), 'hgt': tensor(0., dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "print(allspecies_B_train_set[0])\n",
    "print(allspecies_C_train_set[0])\n",
    "print(allspecies_D_train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria_classifier_B = Classifier(Feedforward(12), torch.nn.BCELoss(), torch.optim.Adam, 0.001)\n",
    "bacteria_classifier_C = Classifier(Feedforward(10), torch.nn.BCELoss(), torch.optim.Adam, 0.001)\n",
    "bacteria_classifier_D = Classifier(Feedforward(4), torch.nn.BCELoss(), torch.optim.Adam, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.3246158487945819\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bacteria_classifier_B\u001b[39m.\u001b[39;49mtrain(allspecies_B_train_set,\u001b[39m2\u001b[39;49m,\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[135], line 39\u001b[0m, in \u001b[0;36mClassifier.train\u001b[0;34m(self, ds, bs, epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(labels)\n\u001b[1;32m     38\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m train_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     41\u001b[0m \u001b[39m# adjust weight\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/eda/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/eda/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bacteria_classifier_B.train(allspecies_B_train_set,2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.223483000962128\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bacteria_classifier_C\u001b[39m.\u001b[39;49mtrain(allspecies_C_train_set,\u001b[39m1\u001b[39;49m,\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[135], line 39\u001b[0m, in \u001b[0;36mClassifier.train\u001b[0;34m(self, ds, bs, epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(labels)\n\u001b[1;32m     38\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m train_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     41\u001b[0m \u001b[39m# adjust weight\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/eda/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/eda/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bacteria_classifier_C.train(allspecies_C_train_set,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bacteria_classifier_D\u001b[39m.\u001b[39;49mtrain(allspecies_D_train_set,\u001b[39m5\u001b[39;49m,\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[16], line 31\u001b[0m, in \u001b[0;36mClassifier.train\u001b[0;34m(self, ds, bs, epoch)\u001b[0m\n\u001b[1;32m     29\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(inputs)\n\u001b[1;32m     30\u001b[0m \u001b[39m# Compute Loss\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(y_pred\u001b[39m.\u001b[39;49msqueeze(), labels)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[1;32m     34\u001b[0m train_loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/eda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/eda/lib/python3.11/site-packages/torch/nn/modules/loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/eda/lib/python3.11/site-packages/torch/nn/functional.py:3089\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3087\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3088\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[0;32m-> 3089\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3092\u001b[0m     )\n\u001b[1;32m   3094\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3095\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "bacteria_classifier_D.train(allspecies_D_train_set,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_csv_list(preprocessed_path):\n",
    "    list_csv_files = []\n",
    "    for path in os.listdir(preprocessed_path):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(preprocessed_path, path)):\n",
    "            list_csv_files.append(os.path.join(preprocessed_path, path))\n",
    "            \n",
    "    return list_csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = create_csv_list(\"../EDA/preprocessed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../EDA/preprocessed_data/bbur.csv', '../EDA/preprocessed_data/bmelic2.csv', '../EDA/preprocessed_data/llac.csv', '../EDA/preprocessed_data/sau2.csv', '../EDA/preprocessed_data/cjen.csv', '../EDA/preprocessed_data/bsub.csv', '../EDA/preprocessed_data/sent.csv', '../EDA/preprocessed_data/vvul1c1.csv', '../EDA/preprocessed_data/nsp.csv', '../EDA/preprocessed_data/atum1c2.csv', '../EDA/preprocessed_data/bhal.csv', '../EDA/preprocessed_data/cperf.csv', '../EDA/preprocessed_data/mtub2.csv', '../EDA/preprocessed_data/bsp.csv', '../EDA/preprocessed_data/nmen1.csv', '../EDA/preprocessed_data/ecoli2.csv', '../EDA/preprocessed_data/pmul.csv', '../EDA/preprocessed_data/spneu1.csv', '../EDA/preprocessed_data/atum2c2.csv', '../EDA/preprocessed_data/sau3.csv', '../EDA/preprocessed_data/mpul.csv', '../EDA/preprocessed_data/fnucl.csv', '../EDA/preprocessed_data/dra1.csv', '../EDA/preprocessed_data/ecoli3.csv', '../EDA/preprocessed_data/ctep.csv', '../EDA/preprocessed_data/cpneu.csv', '../EDA/preprocessed_data/xcamp.csv', '../EDA/preprocessed_data/cglu.csv', '../EDA/preprocessed_data/ctra.csv', '../EDA/preprocessed_data/vcolc2.csv', '../EDA/preprocessed_data/uure.csv', '../EDA/preprocessed_data/vvul2c1.csv', '../EDA/preprocessed_data/xcitri.csv', '../EDA/preprocessed_data/lmono.csv', '../EDA/preprocessed_data/xfas.csv', '../EDA/preprocessed_data/ecoli.csv', '../EDA/preprocessed_data/mlep.csv', '../EDA/preprocessed_data/vcolc1.csv', '../EDA/preprocessed_data/vvul2c2.csv', '../EDA/preprocessed_data/atum2c1.csv', '../EDA/preprocessed_data/spneu2.csv', '../EDA/preprocessed_data/styp.csv', '../EDA/preprocessed_data/cpneu3.csv', '../EDA/preprocessed_data/mpneu.csv', '../EDA/preprocessed_data/dra2.csv', '../EDA/preprocessed_data/cmur.csv', '../EDA/preprocessed_data/caceto.csv', '../EDA/preprocessed_data/aquae.csv', '../EDA/preprocessed_data/ypestis.csv', '../EDA/preprocessed_data/scoel.csv', '../EDA/preprocessed_data/paer.csv', '../EDA/preprocessed_data/rpxx.csv', '../EDA/preprocessed_data/hpyl99.csv', '../EDA/preprocessed_data/atum1c1.csv', '../EDA/preprocessed_data/nmen2.csv', '../EDA/preprocessed_data/hinf.csv', '../EDA/preprocessed_data/mgen.csv', '../EDA/preprocessed_data/spyo.csv', '../EDA/preprocessed_data/mtub.csv', '../EDA/preprocessed_data/rsola.csv', '../EDA/preprocessed_data/rsolac2.csv', '../EDA/preprocessed_data/mloti.csv', '../EDA/preprocessed_data/baphi.csv', '../EDA/preprocessed_data/btheta.csv', '../EDA/preprocessed_data/rconorii.csv', '../EDA/preprocessed_data/tmar.csv', '../EDA/preprocessed_data/linno.csv', '../EDA/preprocessed_data/smel.csv', '../EDA/preprocessed_data/bmelic1.csv', '../EDA/preprocessed_data/sau1.csv', '../EDA/preprocessed_data/synecho.csv', '../EDA/preprocessed_data/cpneu2.csv', '../EDA/preprocessed_data/spyo2.csv', '../EDA/preprocessed_data/tteng.csv', '../EDA/preprocessed_data/ccres.csv', '../EDA/preprocessed_data/hpyl.csv', '../EDA/preprocessed_data/vvul1c2.csv', '../EDA/preprocessed_data/tpal.csv']\n"
     ]
    }
   ],
   "source": [
    "print(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "print(len(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
